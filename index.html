<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PrimEx AI Presenter V2</title>
    <style>
        /* --- STYLING --- */
        body { 
            background: #111; color: #fff; font-family: 'Segoe UI', sans-serif; 
            display: flex; height: 100vh; margin: 0; overflow: hidden; 
        }
        .col { padding: 25px; display: flex; flex-direction: column; gap: 20px; }
        .left { flex: 2; border-right: 1px solid #333; }
        .right { flex: 1; background: #1a1a1a; display: flex; flex-direction: column; position: relative; }
       
        /* PDF STAGE */
        #pdf-stage { 
            flex: 1; background: #000; display: flex; justify-content: center; 
            align-items: center; border: 1px solid #333; border-radius: 12px; overflow: hidden; 
        }
        canvas { max-width: 100%; max-height: 100%; object-fit: contain;}

        /* NEW: CHAT HISTORY (Replaces Caption Box) */
        #chat-history {
            background: #0e0e0e; border: 1px solid #333; border-radius: 8px; padding: 15px;
            height: 150px; overflow-y: auto; font-size: 14px; line-height: 1.5;
            display: flex; flex-direction: column; gap: 10px;
        }
        .msg-row { display: flex; gap: 8px; }
        .msg-role { font-weight: bold; min-width: 40px; }
        .msg-text { color: #ccc; }
        .role-elsa { color: #007bff; }
        .role-user { color: #28a745; }

        /* AVATAR STAGE */
        #avatar-container { 
            height: 300px; width: 100%; background: #000; position: relative; 
            overflow: hidden; border-radius: 12px; border: 1px solid #333;
            transition: all 0.3s ease;
        }
        .brand-badge {
            position: absolute; top: 12px; left: 12px; z-index: 20;
            display: inline-flex; align-items: center; justify-content: center;
            padding: 8px; border-radius: 999px; border: 1px solid #333;
            background: rgba(0, 0, 0, 0.7);
            box-shadow: 0 6px 20px rgba(0,0,0,0.35);
        }
        .brand-badge img { width: 34px; height: 34px; object-fit: contain; }

        video { width: 100%; height: 100%; object-fit: cover; }
        
        /* OVERLAY */
        #connect-overlay {
            position: absolute; inset: 0; background: rgba(0,0,0,0.85); 
            display: flex; justify-content: center; align-items: center; 
            flex-direction: column; gap: 15px; z-index: 10;
        }

        /* CONTROLS */
        .controls { margin-top: auto; display: flex; flex-direction: column; gap: 10px; }
        .btn-group { display: flex; gap: 10px; }
        
        button { 
            padding: 12px; cursor: pointer; background: #333; color: white; 
            border: none; border-radius: 6px; font-weight: 600; font-size: 13px; transition: 0.2s;
        }
        button:hover { background: #444; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        
        .btn-primary { background: #007bff; }
        .btn-primary:hover { background: #0056b3; }
        .btn-danger { background: #dc3545; }
        .btn-danger:hover { background: #a71d2a; }

        .input-group { display: flex; gap: 10px; }
        textarea { 
            flex: 1; padding: 12px; background: #222; color: white; 
            border: 1px solid #444; resize: none; border-radius: 8px; 
            font-family: inherit; outline: none;
        }

        #mic-btn.listening { background: #ff4d4d; animation: pulse 1.5s infinite; }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(255, 77, 77, 0.7); } 100% { box-shadow: 0 0 0 0 rgba(255, 77, 77, 0); } }
        
        .speaking-mode { border-color: #007bff !important; box-shadow: 0 0 20px rgba(0, 123, 255, 0.3); }
    </style>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <script>pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";</script>
</head>
<body>

    <!-- LEFT: SLIDES -->
    <div class="col left">
        <div style="display:flex; justify-content: space-between; align-items: center;">
            <h3 style="margin:0">üìä Presentation Deck</h3>
            <input type="file" id="pdf-input" accept="application/pdf">
        </div>
        <div id="pdf-stage"><canvas id="pdf-canvas"></canvas></div>
    </div>
 
    <!-- RIGHT: AVATAR -->
    <div class="col right">
        <div id="avatar-container">
            <video id="simli-video" autoplay playsinline></video>
            <audio id="simli-audio" autoplay></audio>
            
            <div class="brand-badge">
                <img src="primex%20logo.png" alt="PrimEx logo">
            </div>
            
            <div id="connect-overlay">
                <h2>AI Presenter V2</h2>
                <button id="connect-btn" class="btn-primary">üîå Connect Elsa</button>
            </div>
        </div>

        <div style="text-align:center; font-size:12px; color:#666;" id="status-text">Status: Offline</div>

        <!-- NEW CHAT HISTORY -->
        <div id="chat-history">
            <div style="color:#555; font-style:italic;">Transcript will appear here...</div>
        </div>

        <div class="controls">
            <!-- Navigation Controls -->
            <div class="btn-group">
                <button id="prev-btn" disabled>‚èÆ Prev</button>
                <button id="start-btn" class="btn-primary" style="flex: 1;" disabled>‚ñ∂ Start</button>
                <button id="stop-btn" class="btn-danger" style="width: 60px;" disabled>‚èπ</button>
                <button id="next-btn" disabled>Next ‚è≠</button>
            </div>
            
            <!-- Input Area -->
            <div class="input-group">
                <textarea id="q-input" rows="1" placeholder="Ask a question..."></textarea>
                <button id="mic-btn" title="Speak">üéôÔ∏è</button>
            </div>
            <button id="send-btn" disabled>Send Message</button>
        </div>
    </div>
 
    <!-- LOGIC -->
    <script type="module">
        import { SimliClient } from 'https://esm.sh/simli-client@latest';

        const BASE_URL = 'http://127.0.0.1:3000';
        
        // --- GLOBAL STATE ---
        let pdfDoc = null;
        let currentSlide = 1;      
        let isPresenting = false;  
        let isInterrupted = false; 

        // PRE-FETCHING CACHE
        // Stores promises: { 1: Promise<Data>, 2: Promise<Data> ... }
        let audioCache = {}; 
        
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const simli = new SimliClient();
        
        // Voice Recognition
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = false; recognition.lang = 'en-US';

        // DOM
        const videoEl = document.getElementById('simli-video');
        const audioEl = document.getElementById('simli-audio');
        const statusEl = document.getElementById('status-text');
        const chatLog = document.getElementById('chat-history');
        const avatarContainer = document.getElementById('avatar-container');
        const startBtn = document.getElementById('start-btn');
        const stopBtn = document.getElementById('stop-btn');
        const prevBtn = document.getElementById('prev-btn');
        const nextBtn = document.getElementById('next-btn');

        // --- 1. CONNECT ---
        document.getElementById('connect-btn').onclick = async () => {
            const btn = document.getElementById('connect-btn');
            btn.textContent = "Connecting...";
            try {
                await audioCtx.resume();
                const cfgReq = await fetch(`${BASE_URL}/simli-config`);
                const config = await cfgReq.json();
                
                simli.Initialize({ apiKey: config.apiKey, faceID: config.faceID, handleSilence: true, videoRef: videoEl, audioRef: audioEl });
                await simli.start();
                
                statusEl.textContent = "Status: Online";
                document.getElementById('connect-overlay').style.display = 'none';
                if(pdfDoc) enableControls(true);
                document.getElementById('send-btn').disabled = false;
            } catch (err) {
                alert("Error: " + err.message);
                btn.textContent = "Retry";
            }
        };

        function enableControls(enabled) {
            startBtn.disabled = !enabled;
            prevBtn.disabled = !enabled;
            nextBtn.disabled = !enabled;
        }

        // --- 2. NAVIGATION & STOP ---
        stopBtn.onclick = () => {
            isPresenting = false;
            simli.ClearBuffer();
            statusEl.textContent = `Status: Paused on Slide ${currentSlide}`;
            startBtn.textContent = "‚ñ∂ Resume";
            startBtn.disabled = false;
            stopBtn.disabled = true;
            avatarContainer.classList.remove('speaking-mode');
        };

        nextBtn.onclick = () => { skipToSlide(currentSlide + 1); };
        prevBtn.onclick = () => { skipToSlide(currentSlide - 1); };

        async function skipToSlide(num) {
            if(!pdfDoc || num < 1 || num > pdfDoc.numPages) return;
            
            // Interrupt current flow
            simli.ClearBuffer();
            isPresenting = false; // Temporarily stop loop
            
            // Wait a tiny bit for loop to exit
            await new Promise(r => setTimeout(r, 100));

            currentSlide = num;
            renderPage(currentSlide);
            addLog("System", `Skipped to Slide ${currentSlide}`);
            
            // Reset and restart
            audioCache = {}; // Clear old cache as context changed
            startBtn.click(); // Auto-click start to resume
        }

        // --- 3. THE SMART PRESENTATION LOOP ---
        startBtn.onclick = async () => {
            if(!pdfDoc) return alert("Load PDF first");
            
            isPresenting = true;
            isInterrupted = false;
            
            startBtn.disabled = true;
            stopBtn.disabled = false;
            startBtn.textContent = "Presenting...";

            const totalSlides = pdfDoc.numPages;
            if (currentSlide > totalSlides) currentSlide = 1;

            while (isPresenting && currentSlide <= totalSlides) {
                
                // A. Wait if interrupted by question
                while(isInterrupted && isPresenting) await new Promise(r => setTimeout(r, 500));
                if (!isPresenting) break;

                // B. Render Visuals
                await renderPage(currentSlide);
                statusEl.textContent = `Slide ${currentSlide} of ${totalSlides}`;
                
                // C. Lookahead: Trigger generation for NEXT slide immediately
                if(currentSlide + 1 <= totalSlides) {
                    preloadSlideAudio(currentSlide + 1, totalSlides);
                }

                // D. Speak (Check Cache First or Generate Now)
                // We pass the canvas image data here for Vision
                const imageBase64 = document.getElementById('pdf-canvas').toDataURL('image/jpeg', 0.8);
                
                await playSlideAudio(currentSlide, totalSlides, imageBase64);

                // E. Move Next
                if (isPresenting) currentSlide++; 
            }
            
            if (currentSlide > totalSlides) {
                statusEl.textContent = "Presentation Finished";
                startBtn.textContent = "‚Ü∫ Restart";
                startBtn.disabled = false;
                stopBtn.disabled = true;
                isPresenting = false;
                currentSlide = 1;
            }
        };

        // --- 4. CACHING & PLAYBACK LOGIC ---

        // Helper: Trigger API call but don't wait for result yet. Store the Promise.
        async function preloadSlideAudio(slideIndex, totalSlides) {
            if(audioCache[slideIndex]) return; // Already caching

            // Note: For preloading, we can't easily get the image of the *next* slide 
            // without rendering it invisibly. For V2, we will preload TEXT only context 
            // or we just accept that preloading works best for text, 
            // but for Vision, we might have to wait a bit. 
            // To fix this, we'll only preload if we can. 
            // *Simplified Strategy*: We will NOT send image for preload. 
            // We rely on text for preload, or we just generate on demand.
            
            // For this demo, let's Generate On Demand for current slide to ensure Vision works,
            // but we can optimize later.
            // Returning null here to force on-demand generation for accurate Vision.
            return; 
        }

        async function playSlideAudio(slideIndex, totalSlides, imageBase64) {
            try {
                // 1. Get Text
                const text = await getPageText(slideIndex);
                addLog("System", `Generating audio for Slide ${slideIndex}...`);

                // 2. Fetch Audio (Waiting for API)
                const res = await fetch(`${BASE_URL}/agent/speak`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ 
                        text, 
                        type: 'PRESENT', 
                        slideIndex, 
                        totalSlides, 
                        image: imageBase64 // SENDING IMAGE
                    })
                });
                const data = await res.json();

                if(!isPresenting) return; // Stopped while generating

                addLog("Elsa", data.text);
                
                // 3. Play Audio
                const binaryString = window.atob(data.audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) bytes[i] = binaryString.charCodeAt(i);

                simli.sendAudioData(bytes);

                const durationMs = (bytes.length / 2 / 16000) * 1000;
                
                // 4. Wait for finish (Polling check for Stop button)
                const steps = 20;
                for(let k=0; k<steps; k++) {
                    if(!isPresenting) { simli.ClearBuffer(); return; }
                    await new Promise(r => setTimeout(r, (durationMs + 1000)/steps));
                }

            } catch (err) {
                console.error(err);
                addLog("System", "Error generating audio.");
            }
        }

        // --- 5. INTERACTION (Q&A) ---
        const micBtn = document.getElementById('mic-btn');
        micBtn.onclick = () => {
            if (micBtn.classList.contains('listening')) {
                recognition.stop(); 
            } else {
                isInterrupted = true; simli.ClearBuffer(); 
                recognition.start();
                micBtn.classList.add('listening');
                statusEl.textContent = "Status: Listening...";
            }
        };

        recognition.onresult = (e) => {
            document.getElementById('q-input').value = e.results[0][0].transcript;
            document.getElementById('send-btn').click();
        };
        recognition.onend = () => micBtn.classList.remove('listening');

        document.getElementById('send-btn').onclick = async () => {
            const question = document.getElementById('q-input').value;
            if(!question) return;
            
            addLog("User", question);
            document.getElementById('q-input').value = "";
            
            isInterrupted = true;
            simli.ClearBuffer();
            avatarContainer.classList.add('speaking-mode');

            // Answer Logic
            try {
                const context = await getPageText(currentSlide);
                const res = await fetch(`${BASE_URL}/agent/speak`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ text: question, type: 'ANSWER', context })
                });
                const data = await res.json();
                
                addLog("Elsa", data.text);
                const binaryString = window.atob(data.audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) bytes[i] = binaryString.charCodeAt(i);
                
                simli.sendAudioData(bytes);
                
                // Wait approx duration
                const durationMs = (bytes.length / 2 / 16000) * 1000;
                await new Promise(r => setTimeout(r, durationMs + 500));

            } catch(e) { console.error(e); }

            avatarContainer.classList.remove('speaking-mode');
            if(isPresenting) {
                statusEl.textContent = "Resuming presentation...";
                setTimeout(() => { isInterrupted = false; }, 1000); 
            }
        };

        // --- UI HELPERS ---
        function addLog(role, text) {
            const div = document.createElement('div');
            div.className = "msg-row";
            div.innerHTML = `<div class="msg-role role-${role.toLowerCase()}">${role}:</div><div class="msg-text">${text}</div>`;
            chatLog.appendChild(div);
            chatLog.scrollTop = chatLog.scrollHeight;
        }

        // --- PDF HELPERS ---
        const canvas = document.getElementById('pdf-canvas');
        const ctx = canvas.getContext('2d');
        
        document.getElementById('pdf-input').onchange = async (e) => {
            const file = e.target.files[0];
            const data = new Uint8Array(await file.arrayBuffer());
            pdfDoc = await pdfjsLib.getDocument({ data }).promise;
            currentSlide = 1;
            renderPage(1);
            if(statusEl.textContent.includes("Online")) enableControls(true);
        };

        async function renderPage(num) {
            if(num > pdfDoc.numPages) return;
            const page = await pdfDoc.getPage(num);
            const viewport = page.getViewport({ scale: 1.5 }); // Higher scale for better Vision
            canvas.height = viewport.height;
            canvas.width = viewport.width;
            await page.render({ canvasContext: ctx, viewport: viewport }).promise;
        }
        
        async function getPageText(num) {
            if(num > pdfDoc.numPages) return "";
            const page = await pdfDoc.getPage(num);
            const c = await page.getTextContent();
            return c.items.map(i => i.str).join(' ');
        }
    </script>
</body>
</html>
