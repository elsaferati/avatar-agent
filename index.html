<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PrimEx AI Presenter V2</title>
    <style>
        /* --- STYLING --- */
        body { 
            background: #111; color: #fff; font-family: 'Segoe UI', sans-serif; 
            display: flex; height: 100vh; margin: 0; overflow: hidden; 
        }
        .col { padding: 25px; display: flex; flex-direction: column; gap: 20px; }
        .left { flex: 2; border-right: 1px solid #333; }
        .right { flex: 1; background: #1a1a1a; display: flex; flex-direction: column; position: relative; }
       
        /* PDF STAGE */
        #pdf-stage { 
            flex: 1; background: #000; display: flex; justify-content: center; 
            align-items: center; border: 1px solid #333; border-radius: 12px; overflow: hidden; 
        }
        canvas { max-width: 100%; max-height: 100%; object-fit: contain;}

        /* NEW: CHAT HISTORY (Replaces Caption Box) */
        #chat-history {
            background: #0e0e0e; border: 1px solid #333; border-radius: 8px; padding: 15px;
            height: 150px; overflow-y: auto; font-size: 14px; line-height: 1.5;
            display: flex; flex-direction: column; gap: 10px;
        }
        .msg-row { display: flex; gap: 8px; }
        .msg-role { font-weight: bold; min-width: 40px; }
        .msg-text { color: #ccc; }
        .role-elsa { color: #007bff; }
        .role-user { color: #28a745; }

        /* AVATAR STAGE */
        #avatar-container { 
            height: 300px; width: 100%; background: #000; position: relative; 
            overflow: hidden; border-radius: 12px; border: 1px solid #333;
            transition: all 0.3s ease;
        }
        .brand-badge {
            position: absolute; top: 12px; left: 12px; z-index: 20;
            display: inline-flex; align-items: center; justify-content: center;
            padding: 8px; border-radius: 999px; border: 1px solid #333;
            background: rgba(0, 0, 0, 0.7);
            box-shadow: 0 6px 20px rgba(0,0,0,0.35);
        }
        .brand-badge img { width: 34px; height: 34px; object-fit: contain; }

        video { width: 100%; height: 100%; object-fit: cover; }
        
        /* OVERLAY */
        #connect-overlay {
            position: absolute; inset: 0; background: rgba(0,0,0,0.85); 
            display: flex; justify-content: center; align-items: center; 
            flex-direction: column; gap: 15px; z-index: 10;
        }

        /* CONTROLS */
        .controls { margin-top: auto; display: flex; flex-direction: column; gap: 10px; }
        .btn-group { display: flex; gap: 10px; }
        
        button { 
            padding: 12px; cursor: pointer; background: #333; color: white; 
            border: none; border-radius: 6px; font-weight: 600; font-size: 13px; transition: 0.2s;
        }
        button:hover { background: #444; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        
        .btn-primary { background: #007bff; }
        .btn-primary:hover { background: #0056b3; }
        .btn-danger { background: #dc3545; }
        .btn-danger:hover { background: #a71d2a; }

        .input-group { display: flex; gap: 10px; }
        textarea { 
            flex: 1; padding: 12px; background: #222; color: white; 
            border: 1px solid #444; resize: none; border-radius: 8px; 
            font-family: inherit; outline: none;
        }

        #mic-btn.listening { background: #ff4d4d; animation: pulse 1.5s infinite; }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(255, 77, 77, 0.7); } 100% { box-shadow: 0 0 0 0 rgba(255, 77, 77, 0); } }
        
        .speaking-mode { border-color: #007bff !important; box-shadow: 0 0 20px rgba(0, 123, 255, 0.3); }
    </style>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <script>pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";</script>
</head>
<body>

    <!-- LEFT: SLIDES -->
    <div class="col left">
        <div style="display:flex; justify-content: space-between; align-items: center;">
            <h3 style="margin:0">üìä Presentation Deck</h3>
            <input type="file" id="pdf-input" accept="application/pdf">
        </div>
        <div id="pdf-stage"><canvas id="pdf-canvas"></canvas></div>
    </div>
 
    <!-- RIGHT: AVATAR -->
    <div class="col right">
        <div id="avatar-container">
            <video id="simli-video" autoplay playsinline></video>
            <audio id="simli-audio" autoplay></audio>
            
            <div class="brand-badge">
                <img src="primex%20logo.png" alt="PrimEx logo">
            </div>
            
            <div id="connect-overlay">
                <h2>AI Presenter V2</h2>
                <button id="connect-btn" class="btn-primary">üîå Connect Elsa</button>
            </div>
        </div>

        <div style="text-align:center; font-size:12px; color:#666;" id="status-text">Status: Offline</div>

        <!-- NEW CHAT HISTORY -->
        <div id="chat-history">
            <div style="color:#555; font-style:italic;">Transcript will appear here...</div>
        </div>

        <div class="controls">
            <!-- Navigation Controls -->
            <div class="btn-group">
                <button id="prev-btn" disabled>‚èÆ Prev</button>
                <button id="start-btn" class="btn-primary" style="flex: 1;" disabled>‚ñ∂ Start</button>
                <button id="stop-btn" class="btn-danger" style="width: 60px;" disabled>‚èπ</button>
                <button id="next-btn" disabled>Next ‚è≠</button>
            </div>
            
            <!-- Input Area -->
            <div class="input-group">
                <textarea id="q-input" rows="1" placeholder="Ask a question..."></textarea>
                <button id="mic-btn" title="Speak">üéôÔ∏è</button>
            </div>
            <button id="send-btn" disabled>Send Message</button>
        </div>
    </div>
 
    <!-- LOGIC -->
    <!-- LOGIC -->
    <!-- LOGIC -->
    <script type="module">
        import { SimliClient } from 'https://esm.sh/simli-client@latest';

        const BASE_URL = 'http://127.0.0.1:3000';
        
        // --- GLOBAL STATE ---
        let pdfDoc = null;
        let currentSlide = 1;      
        let isPresenting = false;  
        let isInterrupted = false; 
        
        let slideAbortController = null;
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const simli = new SimliClient();
        
        // Voice Recognition Setup
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = false; 
        recognition.lang = 'en-US';

        // DOM Elements
        const videoEl = document.getElementById('simli-video');
        const audioEl = document.getElementById('simli-audio');
        const statusEl = document.getElementById('status-text');
        const chatLog = document.getElementById('chat-history');
        const avatarContainer = document.getElementById('avatar-container');
        const startBtn = document.getElementById('start-btn');
        const stopBtn = document.getElementById('stop-btn');
        const prevBtn = document.getElementById('prev-btn');
        const nextBtn = document.getElementById('next-btn');
        const micBtn = document.getElementById('mic-btn');
        let slidesSinceLastAsk = 0;
        let recentUserQuestion = false;

        // --- 1. CONNECT ---
        document.getElementById('connect-btn').onclick = async () => {
            const btn = document.getElementById('connect-btn');
            btn.textContent = "Connecting...";
            try {
                await audioCtx.resume();
                const cfgReq = await fetch(`${BASE_URL}/simli-config`);
                const config = await cfgReq.json();
                
                simli.Initialize({ apiKey: config.apiKey, faceID: config.faceID, handleSilence: true, videoRef: videoEl, audioRef: audioEl });
                await simli.start();
                
                statusEl.textContent = "Status: Online";
                document.getElementById('connect-overlay').style.display = 'none';
                if(pdfDoc) enableControls(true);
                document.getElementById('send-btn').disabled = false;
            } catch (err) {
                alert("Error: " + err.message);
                btn.textContent = "Retry";
            }
        };

        function enableControls(enabled) {
            startBtn.disabled = !enabled;
            prevBtn.disabled = !enabled;
            nextBtn.disabled = !enabled;
        }

        // --- 2. AUDIO PLAYBACK HELPER ---
        async function playAudioData(base64Audio) {
            const binaryString = window.atob(base64Audio);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) bytes[i] = binaryString.charCodeAt(i);
            
            simli.sendAudioData(bytes);

            // Calculate duration to wait
            const durationMs = (bytes.length / 2 / 16000) * 1000;
            await new Promise(r => setTimeout(r, durationMs + 200)); 
        }

        // --- 3. UNIFIED INPUT LOGIC (TEXT & VOICE) ---

       // A. Shared Function: Handles "Did the user say Question or Continue?"
        async function processUserInput(userText) {
            if (!userText.trim()) return;

            // Stop mic to prevent double input
            try { recognition.stop(); } catch(e){}
            micBtn.classList.remove('listening');

            addLog("User", userText);
            document.getElementById('q-input').value = ""; // Clear Input

            statusEl.textContent = "Status: Thinking...";
            
            try {
                // 1. Ask Backend Intent
                const checkRes = await fetch(`${BASE_URL}/agent/speak`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ text: userText, type: 'DECIDE_NEXT_MOVE' })
                });
                const decision = await checkRes.json();

                if (decision.action === "RESUME") {
                    
                    // --- NEW LOGIC: CHECK IF WE NEED A RECAP ---
                    if (recentUserQuestion) {
                        addLog("System", "Generating Recap...");
                        statusEl.textContent = "Status: Recapping...";
                        
                        // Get current slide context again
                        const context = await getPageText(currentSlide);
                        
                        // Call Backend for Recap
                        const recapRes = await fetch(`${BASE_URL}/agent/speak`, {
                            method: 'POST',
                            headers: {'Content-Type': 'application/json'},
                            body: JSON.stringify({ 
                                text: context, 
                                type: 'RECAP', 
                                slideIndex: currentSlide 
                            })
                        });
                        const recapData = await recapRes.json();
                        
                        // Play the Recap Audio
                        addLog("Elsa", recapData.text);
                        await playAudioData(recapData.audio);
                    }
                    
                    // --- NORMAL RESUME ---
                    addLog("System", "Resuming presentation...");
                    statusEl.textContent = "Status: Resuming...";
                    
                    isInterrupted = false; // Unpauses the loop
                    recentUserQuestion = false; // Reset the flag
                    
                    // If the user hit "Stop" manually earlier, we might need to restart the loop manually
                    if (!isPresenting) {
                        startBtn.click();
                    }

                } else {
                    // It is a question
                    recentUserQuestion = true; // Mark that a question happened
                    await handleQuestionLoop(userText);
                }
            } catch (err) {
                console.error(err);
                statusEl.textContent = "Error processing input";
            }
        }

        // B. Handle Question & Follow-up
        async function handleQuestionLoop(questionText) {
            avatarContainer.classList.add('speaking-mode');
            const context = await getPageText(currentSlide);
            
            const res = await fetch(`${BASE_URL}/agent/speak`, {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({ text: questionText, type: 'ANSWER', context })
            });
            const data = await res.json();
            
            addLog("Elsa", data.text);
            await playAudioData(data.audio);
            
            avatarContainer.classList.remove('speaking-mode');

            // Listen again for follow-up
            startAutoListening();
        }

        // Decide if we should ask a checkpoint question
        async function shouldAskQuestion(slideText, slideIndex, totalSlides, sinceLastAsk, hadRecentUserQuestion) {
            try {
                const res = await fetch(`${BASE_URL}/agent/speak`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ 
                        text: slideText,
                        type: 'SHOULD_ASK',
                        slideIndex,
                        totalSlides,
                        slidesSinceLastAsk: sinceLastAsk,
                        recentUserQuestion: hadRecentUserQuestion
                    })
                });
                const data = await res.json();
                return !!data.ask;
            } catch (err) {
                console.error("Should-ask decision failed:", err);
                return false;
            }
        }

        // C. Start Microphone
        function startAutoListening() {
            console.log("üé§ Auto-listening...");
            statusEl.textContent = "Status: Waiting for input...";
            micBtn.classList.add('listening');
            try { recognition.start(); } catch(e) { console.warn("Mic already on"); }
        }

        // --- EVENT LISTENERS FOR INPUT ---

        // 1. Voice Result
        recognition.onresult = (e) => {
            const transcript = e.results[0][0].transcript;
            document.getElementById('q-input').value = transcript;
            processUserInput(transcript); 
        };

        // 2. Send Button Click
        document.getElementById('send-btn').onclick = () => {
            const text = document.getElementById('q-input').value;
            processUserInput(text);
        };

        // 3. Enter Key Press
        document.getElementById('q-input').addEventListener("keypress", function(event) {
            if (event.key === "Enter") {
                event.preventDefault();
                document.getElementById('send-btn').click();
            }
        });

        // 4. Mic Button Click (Manual)
        micBtn.onclick = () => {
            startAutoListening();
        };


       // --- 4. PRESENTATION LOOP ---
        startBtn.onclick = async () => {
            if(!pdfDoc) return alert("Load PDF first");
            
            isPresenting = true;
            isInterrupted = false;
            slidesSinceLastAsk = 0;
            recentUserQuestion = false;
            
            startBtn.disabled = true;
            stopBtn.disabled = false;
            startBtn.textContent = "Presenting...";

            const totalSlides = pdfDoc.numPages;
            // Ensure we don't skip slides accidentally after restart
            if (currentSlide > totalSlides) currentSlide = 1;

            while (isPresenting && currentSlide <= totalSlides) {
                
                // A. Render
                await renderPage(currentSlide);
                statusEl.textContent = `Slide ${currentSlide} of ${totalSlides}`;
                
                // B. Generate Audio
                const imageBase64 = document.getElementById('pdf-canvas').toDataURL('image/jpeg', 0.8);
                const text = await getPageText(currentSlide);
                
                addLog("System", `Slide ${currentSlide}: Generating...`);
                
                try {
                    const res = await fetch(`${BASE_URL}/agent/speak`, {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({ text, type: 'PRESENT', slideIndex: currentSlide, totalSlides, image: imageBase64 })
                    });
                    
                    const data = await res.json();

                    // --- ERROR CHECK ---
                    if (data.error) {
                        addLog("System", "‚ùå Error: " + data.error);
                        console.error(data.error);
                        break; // Stop presentation on error
                    }
                    
                    if (!isPresenting) break; 

                    // C. Speak
                    if (data.text) {
                        addLog("Elsa", data.text);
                        if (data.audio) await playAudioData(data.audio);
                    } else {
                        addLog("System", "Error: Received empty response from brain.");
                    }

                    // --- D. CHECKPOINT: Ask for questions (LLM decides) ---
                    if (isPresenting && currentSlide < totalSlides) {
                        const shouldAsk = await shouldAskQuestion(text, currentSlide, totalSlides, slidesSinceLastAsk, recentUserQuestion);
                        if (shouldAsk) {
                            const checkText = "Does that make sense, or do you have any questions?";
                            
                            const ttsRes = await fetch(`${BASE_URL}/agent/speak`, {
                                method: 'POST',
                                headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: checkText, type: 'TTS_ONLY' })
                            });
                            const ttsData = await ttsRes.json();
                            await playAudioData(ttsData.audio);

                            // PAUSE and LISTEN
                            isInterrupted = true;
                            startAutoListening();
                            slidesSinceLastAsk = 0;
                            recentUserQuestion = false;

                            // Wait loop
                            statusEl.textContent = "Status: Waiting for user input...";
                            while(isInterrupted && isPresenting) {
                                await new Promise(r => setTimeout(r, 500));
                            }
                        } else {
                            slidesSinceLastAsk += 1;
                        }
                    }

                    if (isPresenting) currentSlide++; 

                } catch (err) {
                    addLog("System", "‚ùå Connection Error: " + err.message);
                    break;
                }
            }
            
            if (currentSlide > totalSlides) {
                statusEl.textContent = "Presentation Finished";
                startBtn.textContent = "‚Ü∫ Restart";
                startBtn.disabled = false;
                stopBtn.disabled = true;
                isPresenting = false;
                currentSlide = 1;
            }
        };

        // --- 5. STOP ---
        stopBtn.onclick = () => {
            isPresenting = false;
            isInterrupted = false;
            simli.ClearBuffer();
            statusEl.textContent = "Stopped";
            startBtn.disabled = false;
            stopBtn.disabled = true;
            micBtn.classList.remove('listening');
        };

        // --- HELPERS ---
        function addLog(role, text) {
            const div = document.createElement('div');
            div.className = "msg-row";
            div.innerHTML = `<div class="msg-role role-${role.toLowerCase()}">${role}:</div><div class="msg-text">${text}</div>`;
            chatLog.appendChild(div);
            chatLog.scrollTop = chatLog.scrollHeight;
        }

        const canvas = document.getElementById('pdf-canvas');
        const ctx = canvas.getContext('2d');
        
        document.getElementById('pdf-input').onchange = async (e) => {
            const file = e.target.files[0];
            const data = new Uint8Array(await file.arrayBuffer());
            pdfDoc = await pdfjsLib.getDocument({ data }).promise;
            currentSlide = 1;
            renderPage(1);
            if(statusEl.textContent.includes("Online")) enableControls(true);
        };

        async function renderPage(num) {
            if(num > pdfDoc.numPages) return;
            const page = await pdfDoc.getPage(num);
            const viewport = page.getViewport({ scale: 1.5 });
            canvas.height = viewport.height;
            canvas.width = viewport.width;
            await page.render({ canvasContext: ctx, viewport: viewport }).promise;
        }
        
        async function getPageText(num) {
            if(num > pdfDoc.numPages) return "";
            const page = await pdfDoc.getPage(num);
            const c = await page.getTextContent();
            return c.items.map(i => i.str).join(' ');
        }
    </script>
</body>
</html>
